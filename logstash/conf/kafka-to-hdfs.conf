input {
 kafka {
   #读取生产环境kafka_2.10-0.10.1.0 topic中的数据
   bootstrap_servers => "kafka-1:9094,kafka-2:9094,kafka-3:9094,kafka-4:9094,kafka-5:9094,kafka-6:9094"
   group_id => "test-group"
   topics => ["product-processed-log"]
   codec => "json"
   consumer_threads => 6
  }
}

output {
  webhdfs {
   #配置namenode alive状态的主机
    host => "bigdata-128-13"
    port => 50070
    standby_host => "bigdata-128-1"
    standby_port => 50070
    path => "/test2/%{+YYYY-MM-dd}/logstash-%{+HH}.log"
    user => "xxx"
    codec => "json"
  }
  #used to compare file which send to Hdfs
  file {
    #codec can't be json and plain,just not set
    path => "/data/logs/logstash_v5/xxxxxx/abc-output.log"
  }
}

使用logstash的webhdfs插件，用来将kafka的日志写入Hdfs中，是不能用于生产环境的。
因为当强行kill -9 这个logstash进程，再次启动，发现日志重复写入了。
测试3万行日志，像上面操作试验，最终写入hdfs的日志条数是3万2千多行。

耗费将近1天的时间做这个事情，准备测试数据，插件配置等，测试结果是插件不满足线上使用。
吸取的经验教训:首先用脑去思考，logstash里的kafka input插件，在强行kill后，是否能准确记录offset位置。
以及webhdfs插件的可用性（所依赖的hdfs版本，以及本身所依赖的webhdfs的最新更新时间），本以为一两个小时就可以搞定，
结果陷入进去，浪费了时间，切记。
